<h1>Results</h1>

The directory in which this program is run contains a example parameter file by defualt.
If you do not specify a parameter file as an argument on the command
line, the program will try to read the file "`parameters.prm`" by default, and
will execute the two dimensional version of the code.

Regardless of the specific parameter file name, if the specified file does not
exist when you execute the program you will get an exception that no such file
can be found:

@code
----------------------------------------------------
Exception on processing:

--------------------------------------------------------
An error occurred in line <74> of file <../source/base/parameter_acceptor.cc> in function
    static void dealii::ParameterAcceptor::initialize(const std::string &, const std::string &, const ParameterHandler::OutputStyle, dealii::ParameterHandler &)
The violated condition was:
    false
Additional information:
    You specified <parameters.prm> as input parameter file, but it does not exist. We created it for you.
--------------------------------------------------------

Aborting!
----------------------------------------------------
@endcode

However, as the error message already states, the code that triggers the
exception will also generate the specified file ("`parameters.prm`" in this case).

On any number of core, the simulation output will look like:

@code
bash$ mpirun -np 4 ./step-68 parameters.prm
Number of particles inserted: 606
Repartitioning triangulation after particle generation
Writing particle output file: analytical-particles-0
Writing background field file: background-0
Writing particle output file: analytical-particles-10
Writing background field file: background-10
Writing particle output file: analytical-particles-20
Writing background field file: background-20
Writing particle output file: analytical-particles-30
Writing background field file: background-30
...
Number of particles inserted: 606
Repartitioning triangulation after particle generation
Writing particle output file: analytical-particles-0
Writing background field file: background-0
Writing particle output file: analytical-particles-10
Writing background field file: background-10
Writing particle output file: analytical-particles-20
Writing background field file: background-20
Writing particle output file: analytical-particles-30
Writing background field file: background-30
...
Writing particle output file: interpolated-particles-1980
Writing background field file: background-1980
Writing particle output file: interpolated-particles-1990
Writing background field file: background-1990
Writing particle output file: interpolated-particles-2000
Writing background field file: background-2000
@endcode

We note that, by default, the simulation runs the particle tracking with
an analytical velocity for 2000 iterations, then runs the particle tracking with
velocity interpolationn for the same duration. The results are written every
10th iteration.

<h3> Motion of the particles </h3>

The following animation displays the trajectory of the particles as they
are advected by the flow field. We see that after the complete duration of the
flow, the particle go back to their initial configuration as is expected.

@htmlonly
<p align="center">
  <iframe width="560" height="500" src="https://youtu.be/EbgS5Ch35Xs"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly

<h3> Dynamic load balancing </h3>

The following animation shows the impact of dynamic load balancing. We clearly
see that the subdomains adapt themselves to balance the number of particles per
subdomain. However, a perfect load balancing is not reached, in part due to
the coarseness of the background mesh.

@htmlonly
<p align="center">
  <iframe width="560" height="500" src="https://youtu.be/ubUcsR4ECj4"
   frameborder="0"
   allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
   allowfullscreen></iframe>
 </p>
@endhtmlonly


<h3>Possibilities for extensions</h3>

This steps highlights some of the main capabilities of particle, notably their
capacity to be use in distributed parallel simulations. However, this step could
be exteded in numerous manners:
- High-order time integration (for example using a Runge-Kutta 4 method) could be
used to increase the accuracy and allow for an increased time-steps.
- The full equation of motion (with inertia) could be solved for the particles. In
this case the particles would need to have additional properties such as their mass,
and their diameter.
- Coupling to a flow solver. This step could be straightforwardly coupled to any parallel
steps in which the Stokes or the Navier-Stokes equations are solved (e.g. step-57)
